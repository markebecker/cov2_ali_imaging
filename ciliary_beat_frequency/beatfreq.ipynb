{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1402f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the point of this notebook is to take ciliary beat frequency videos from KO cultures (no reference images),\n",
    "# process them, and concatenate the resulting csvs into something that can be analyzed in r.\n",
    "\n",
    "# requires:\n",
    "# - beat frequency videos (256x256 .dvs with framerate = 8 ms)\n",
    "# - csv key to points (culturepoint, vidpoint.start, vidpoint.end, donor, condition)\n",
    "# optional:\n",
    "# - reference images (1024 x 1024 (or 256x256...) .dv files, 4 channel)\n",
    "\n",
    "# because the name scheme of every experiment was different, it is very important to check that everything is matched correctly\n",
    "# refs and vids\n",
    "# and then vidpoints to culturepoints.\n",
    "# I had to manually edit concatenate_csvs for most experiments.\n",
    "# The specific lines that probably need editing are commented in all caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31eeeb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import os # navigating file system\n",
    "import mrc # opening .dv files\n",
    "from natsort import natsorted # dealing with file pairs where one is named _01.dv and the other is _1.dv.\n",
    "import numpy as np # numbers\n",
    "import scipy # signal processing\n",
    "from skimage import io as skio # for saving tif\n",
    "import csv # writing csv\n",
    "import datetime\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd # for dataframe handling\n",
    "\n",
    "# define functions\n",
    "\n",
    "# write a log file so i can have some info about how the function was run\n",
    "# ideally i would also include the specific code that was run however that seems to be pretty hard !\n",
    "def generate_log(log_file_path):\n",
    "    # get current date and time\n",
    "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # get package versions\n",
    "    try:\n",
    "        package_versions = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze']).decode('utf-8')\n",
    "    except subprocess.CalledProcessError:\n",
    "        package_versions = \"Failed to retrieve package versions.\"\n",
    "\n",
    "    # create the log content\n",
    "    log_content = f\"Date: {current_date}\\n\\n\"\n",
    "    log_content += f\"Code from ciliako_processing\\n\\n\"\n",
    "    log_content += \"Package versions:\\n\"\n",
    "    log_content += package_versions\n",
    "\n",
    "    # Write log content to the log file\n",
    "    with open(log_file_path, 'w') as log_file:\n",
    "        log_file.write(log_content)\n",
    "\n",
    "\n",
    "\n",
    "# look at files in a folder and find .dvs with ref in the appropriate position + matched non ref\n",
    "# This particular iteration can handle refs or vids in tif or dv format.\n",
    "def organize(folder):\n",
    "    list = natsorted(os.listdir(folder))\n",
    "    cilialist = []\n",
    "    reflist = []\n",
    "    \n",
    "    for m in list:\n",
    "        if (m.endswith('.dv') or m.endswith('.tif')) and 'ref' not in m:\n",
    "            cilialist.append(m)\n",
    "        elif (m.endswith('.dv') or m.endswith('.tif')) and 'ref' in m:\n",
    "            reflist.append(m)\n",
    "    return cilialist, reflist\n",
    "\n",
    "# calculate power and dominant frequency for each pixel\n",
    "def powerfreq_all(pix):\n",
    "    f, pxx = scipy.signal.periodogram(pix, fs=125)\n",
    "    max_pxx = np.max(pxx)\n",
    "    index = np.where(pxx == max_pxx)\n",
    "    domfreq = f[index]\n",
    "    return domfreq[0], max_pxx\n",
    "\n",
    "\n",
    "# the big function. works for videos with and without reference images.\n",
    "def perpair_processing(folder):\n",
    "    # Create processed folder if it doesn't exist\n",
    "    processed_folder = os.path.join(folder, 'processed')\n",
    "    os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    # Get lists of all the ciliavids and ref images in the folder\n",
    "    ciliavids, refimgs = organize(folder)\n",
    "\n",
    "    for x in range(len(ciliavids)):\n",
    "        current = ciliavids[x]\n",
    "        if x < len(refimgs):\n",
    "            refname = refimgs[x]\n",
    "        else:\n",
    "            refname = None\n",
    "        print('Reference: ' + str(refname))\n",
    "        print('Video: ' + current)\n",
    "\n",
    "        # Read cilia video\n",
    "        if current.endswith('.dv'):\n",
    "            # Read DV \n",
    "            image = mrc.imread(os.path.join(folder, current))\n",
    "        elif current.endswith('.tif'):\n",
    "            # Read TIFF image using skimage\n",
    "            image = skio.imread(os.path.join(folder, current))\n",
    "        rows, cols = image.shape[1:]\n",
    "        \n",
    "        # Read matched reference image\n",
    "        if refname:\n",
    "            if refname.endswith('.dv'):\n",
    "                refimage = mrc.imread(os.path.join(folder, refname))\n",
    "            elif refimage.endswith('.tif'):\n",
    "                refimage = skio.imread(os.path.join(folder, refname))\n",
    "            refproj = refimage.max(axis=1)\n",
    "            if refproj.shape[1] > 256: #there was an incident where some reference iamges were not 1024 x 1024\n",
    "                refcent = refproj[:, 383:639, 383:639]\n",
    "            else:\n",
    "                refcent = refproj\n",
    "        else:\n",
    "            refcent = np.empty((4, rows, cols))\n",
    "            refcent.fill(np.nan)\n",
    "\n",
    "        # Create empty arrays for storing pixel values\n",
    "        power = np.empty((rows, cols))\n",
    "        domfreq = np.empty((rows, cols))\n",
    "        sumproj = np.empty((rows, cols))\n",
    "        refintensity = np.empty((4, rows, cols))\n",
    "\n",
    "        # Process each pixel\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                domfreq[i, j], power[i, j] = powerfreq_all(image[:, i, j])\n",
    "                sumproj[i, j] = image[:, i, j].sum()\n",
    "                refintensity[:, i, j] = refcent[:, i, j]\n",
    "\n",
    "        # Save power, dominant frequency, sum projection, and reference image intensity as TIFF\n",
    "        output_tiff = np.concatenate((power[np.newaxis, :, :], domfreq[np.newaxis, :, :],\n",
    "                                      sumproj[np.newaxis, :, :], refintensity), axis=0)\n",
    "        tiff_filename = os.path.join(processed_folder, current[:-4] + '_nugget.tif')\n",
    "        skio.imsave(tiff_filename, output_tiff, check_contrast=False)\n",
    "        print('Saved: ' + tiff_filename)\n",
    "\n",
    "        # Save pixel values as CSV\n",
    "        output_csv = np.column_stack((np.repeat(current, rows*cols),\n",
    "                                      np.repeat(refname, rows*cols),\n",
    "                                      np.repeat(np.arange(rows), cols),\n",
    "                                      np.tile(np.arange(cols), rows),\n",
    "                                      power.ravel(), domfreq.ravel(), sumproj.ravel(),\n",
    "                                      refintensity.reshape(4, -1).T))\n",
    "        csv_filename = os.path.join(processed_folder, current[:-4] + '_perpixsummary.csv')\n",
    "        with open(csv_filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['video', 'refimage', 'i', 'j', 'power', 'domfreq', 'sumproj',\n",
    "                             'spytub', 'nucview', 'gfp', 'pol'])\n",
    "            writer.writerows(output_csv)\n",
    "        print('Saved: ' + csv_filename)\n",
    "    logfilepath = folder + 'processed/log.txt'\n",
    "    generate_log(logfilepath)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bceca377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### concatenate the csvs and add extra info ###\n",
    "\n",
    "def concatenate_csvs(folder, mapping_csv, timepoints_csv):\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder) if file.endswith('.csv')]\n",
    "\n",
    "    # Read the mapping CSV file\n",
    "    mapping_df = pd.read_csv(mapping_csv)\n",
    "    timepoints_df = pd.read_csv(timepoints_csv)\n",
    "    \n",
    "    # Create an empty list to store the concatenated dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over the CSV files\n",
    "    for file in csv_files:\n",
    "        # Read each CSV file\n",
    "        csv_path = os.path.join(folder, file)\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Extract the file information from the filename. Owing to the nature of image acquisition,\n",
    "        # this will probably need adjustment for every experiment.\n",
    "        filename = os.path.splitext(file)[0]\n",
    "        timepoint = int(filename.split('_')[3][1:]) # CHANGE THIS FOR YOUR EXPERIMENT OF INTEREST\n",
    "        point = int(filename.split('_')[4]) # CHANGE THIS FOR YOUR EXPERIMENT OF INTEREST\n",
    "\n",
    "        # Lookup donor and mock/infected information from the mapping CSV\n",
    "        # first, find the row of the mapping_df that has the correct info\n",
    "        mask = (mapping_df['vidpoint.start'] <= point) & (mapping_df['vidpoint.end'] >= point)\n",
    "        # then, take the info we need from that row\n",
    "        donor = int(mapping_df.loc[mask, 'donor'].values[0])\n",
    "        condition = mapping_df.loc[mask, 'condition'].values[0]\n",
    "        culturepoint = int(mapping_df.loc[mask, 'culturepoint'].values[0])\n",
    "        experiment = mapping_df.loc[mask, 'experiment'].values[0]\n",
    "        \n",
    "        # Lookup hpi from other mapping csv\n",
    "        hpi = timepoints_df.loc[timepoints_df['timepoints'] == timepoint, 'hpi'].values[0]\n",
    "        \n",
    "        # Add the additional columns\n",
    "        df['donor'] = donor\n",
    "        df['vidpoint'] = point\n",
    "        df['condition'] = condition\n",
    "        df['culturepoint'] = culturepoint\n",
    "        df['experiment'] = experiment\n",
    "        df['timepoint'] = timepoint\n",
    "        df['hpi'] = hpi\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dfs.append(df)\n",
    "        print(f'appended file {filename} donor {donor} {condition} pt# {culturepoint} time {hpi}')\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    result_df = pd.concat(dfs)\n",
    "\n",
    "    # Save the concatenated dataframe to a new CSV file\n",
    "    output_csv = os.path.join(folder, 'concatenated.csv')\n",
    "    result_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    ## Make a little sample of the big csv file so I can quick look at things in R with less suffering\n",
    "    small_output_csv = os.path.join(folder, 'concatenated_smol.csv')\n",
    "    total_rows = result_df.shape[0]\n",
    "    n = int(total_rows * 0.05)\n",
    "    smol_result_df = result_df.sample(n=n, replace = False)\n",
    "    smol_result_df.to_csv(small_output_csv, index=False)\n",
    "\n",
    "    print('Concatenated CSV saved as: ' + output_csv)\n",
    "\n",
    "\n",
    "# Usage\n",
    "#folder = '/Users/Confocal/Desktop/ciliabulk2/processed/'\n",
    "#mapping_csv = '/Users/Confocal/Desktop/ciliabulk2/cilia_ptskey.csv'\n",
    "#timepoints_csv = '/Users/Confocal/Desktop/ciliabulk2/timepoints.csv'\n",
    "\n",
    "#folder = 'D:/ciliako44/ciliavids/denoised/processed/'\n",
    "#mapping_csv = 'D:/ciliako44/ciliako44_pts.csv'\n",
    "\n",
    "\n",
    "#concatenate_csvs(folder, mapping_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: calculating beat frequency & making .csvs and image nuggets.\n",
    "folder = 'D:/longcilia/denoised/unmatched/'\n",
    "mk = perpair_processing(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d50e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage: matching up the .csvs to relevant experimental info such as donor, condition, mock or infected, etc.\n",
    "folder = 'D:/ciliakos_all/denoised/processed/ciliako44/'\n",
    "mapping_csv = 'D:/ciliakos_all/denoised/processed/ciliako44_pts.csv'\n",
    "timepoints_csv = 'D:/ciliakos_all/denoised/processed/ciliako44_timepoints.csv'\n",
    "\n",
    "concatenate_csvs(folder, mapping_csv, timepoints_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env-testing",
   "language": "python",
   "name": "napari-env-testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
